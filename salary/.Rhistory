card_tab$Legendary <- 0
card_tab$Legendary[grep("Legendary", card_tab$supertypes)] <- 1
types_tab <- as.data.table(tstrsplit(card_tab$types," "))
types_tab$id <- card_tab$id
types_tab
m_types_tab <- melt(types_tab,id.vars = "id")
m_types_tab
m_types_tab <- m_types_tab[!is.na(m_types_tab$value)]
m_types_tab$True <- 1
types_tab <- dcast(m_types_tab,id ~ value,length,value.var="True")
types_tab
master
master <- merge(master,card_tab[,.(id,rarity,Legendary)],all.x=T)
master
master <- merge(master,types_tab,all.x=T)
master
master$current_price[is.na(master$current_price)] <- mean(master$current_price, na.rm = T)
master
master[is.na(master)] <- 0
############################
# split back to train/test #
############################
# split
train <- master[train==1]
test <- master[train==0]
# clean up columns
train$train <- NULL
test$train <- NULL
test$future_price <- NULL
########################
# write out to interim #
########################
fwrite(train,file.path(interim_data_path,"train_v1.csv"))
fwrite(test,file.path(interim_data_path,"test_v1.csv"))
rm(list = ls())
rm(list = ls())
library(data.table)
library(caret)
library(Metrics)
library(glmnet)
library(plotmo)
library(lubridate)
interim_data_path = "~/Desktop/STAT380/themagic/project/volume/data/interim/"
model_path ="~/Desktop/STAT380/themagic/project/volume/models/"
submission_path = "~/Desktop/STAT380/themagicproject/volume/data/processed/"
raw_path = "~/Desktop/STAT380/themagic/project/volume/data/raw/"
train = fread(file.path(interim_data_path,"train_v1.csv"))
test = fread(file.path(interim_data_path,"test_v1.csv"))
example_sub = fread(file.path(raw_path,"example_submission.csv"))
install.packages(glmnet)
install.packages("glmnet")
rm(list = ls())
library(data.table)
library(caret)
library(Metrics)
library(glmnet)
library(plotmo)
library(lubridate)
interim_data_path = "~/Desktop/STAT380/themagic/project/volume/data/interim/"
model_path ="~/Desktop/STAT380/themagic/project/volume/models/"
submission_path = "~/Desktop/STAT380/themagicproject/volume/data/processed/"
raw_path = "~/Desktop/STAT380/themagic/project/volume/data/raw/"
train = fread(file.path(interim_data_path,"train_v1.csv"))
test = fread(file.path(interim_data_path,"test_v1.csv"))
example_sub = fread(file.path(raw_path,"example_submission.csv"))
rm(list = ls())
library(data.table)
library(caret)
library(Metrics)
library(glmnet)
library(plotmo)
library(lubridate)
interim_data_path = "~/Desktop/STAT380/themagic/project/volume/data/interim/"
model_path ="~/Desktop/STAT380/themagic/project/volume/models/"
submission_path = "~/Desktop/STAT380/themagicproject/volume/data/processed/"
raw_path = "~/Desktop/STAT380/themagic/project/volume/data/raw/"
train = fread(file.path(interim_data_path,"train_v1.csv"))
test = fread(file.path(interim_data_path,"test_v1.csv"))
example_sub = fread(file.path(raw_path,"example_submission.csv"))
test$future_price <- 0
rm(list = ls())
rm(list = ls())
library(data.table)
library(caret)
library(Metrics)
library(glmnet)
library(plotmo)
library(lubridate)
interim_data_path = "~/Desktop/STAT380/themagic/project/volume/data/interim/"
model_path ="~/Desktop/STAT380/themagic/project/volume/models/"
submission_path = "~/Desktop/STAT380/themagicproject/volume/data/processed/"
raw_path = "~/Desktop/STAT380/themagic/project/volume/data/raw/"
train = fread(file.path(interim_data_path,"train_v1.csv"))
test = fread(file.path(interim_data_path,"test_v1.csv"))
example_sub = fread(file.path(raw_path,"example_submission.csv"))
test$future_price <- 0
View(test)
year_num <- as.numeric(as.factor(year(as_date(train$current_date))))
# subset out only the columns to model
train
test
View(train)
drops <-  c('id','future_date','current_date')
train <- train[, !drops, with = FALSE]
train
test <- test[, !drops, with = FALSE]
test
rm(list = ls())
library(data.table)
library(caret)
library(Metrics)
library(glmnet)
library(plotmo)
library(lubridate)
interim_data_path = "~/Desktop/STAT380/themagic/project/volume/data/interim/"
model_path ="~/Desktop/STAT380/themagic/project/volume/models/"
submission_path = "~/Desktop/STAT380/themagicproject/volume/data/processed/"
raw_path = "~/Desktop/STAT380/themagic/project/volume/data/raw/"
train = fread(file.path(interim_data_path,"train_v1.csv"))
test = fread(file.path(interim_data_path,"test_v1.csv"))
example_sub = fread(file.path(raw_path,"example_submission.csv"))
test$future_price <- 0
year_num <- as.numeric(as.factor(year(as_date(train$current_date))))
# subset out only the columns to model
train
test
drops <-  c('id','future_date','current_date')
train <- train[, !drops, with = FALSE]
train
test <- test[, !drops, with = FALSE]
test
#save the response var because dummyVars will remove
#train_y <- train$future_price
#train_y
# work with dummies
dummies  <-  dummyVars(future_price ~ ., data = train)
View(dummies)
rm(list = ls())
library(data.table)
library(caret)
library(Metrics)
library(glmnet)
library(plotmo)
library(lubridate)
interim_data_path = "~/Desktop/STAT380/themagic/project/volume/data/interim/"
model_path ="~/Desktop/STAT380/themagic/project/volume/models/"
submission_path = "~/Desktop/STAT380/themagicproject/volume/data/processed/"
raw_path = "~/Desktop/STAT380/themagic/project/volume/data/raw/"
train = fread(file.path(interim_data_path,"train_v1.csv"))
test = fread(file.path(interim_data_path,"test_v1.csv"))
example_sub = fread(file.path(raw_path,"example_submission.csv"))
test$future_price <- 0
year_num <- as.numeric(as.factor(year(as_date(train$current_date))))
# subset out only the columns to model
train
test
drops <-  c('id','future_date','current_date')
train <- train[, !drops, with = FALSE]
train
test <- test[, !drops, with = FALSE]
test
#save the response var because dummyVars will remove
train_y <- train$future_price
train_y
# work with dummies
dummies  <-  dummyVars(future_price ~ ., data = train)
train <- predict(dummies, newdata = train)
test <- predict(dummies, newdata = test)
train <- data.table(train)
test <- data.table(test)
train <- as.matrix(train)
train
View(train)
rm(list = ls())
library(data.table)
library(caret)
library(Metrics)
library(glmnet)
library(plotmo)
library(lubridate)
interim_data_path = "~/Desktop/STAT380/themagic/project/volume/data/interim/"
model_path ="~/Desktop/STAT380/themagic/project/volume/models/"
submission_path = "~/Desktop/STAT380/themagicproject/volume/data/processed/"
raw_path = "~/Desktop/STAT380/themagic/project/volume/data/raw/"
train = fread(file.path(interim_data_path,"train_v1.csv"))
test = fread(file.path(interim_data_path,"test_v1.csv"))
example_sub = fread(file.path(raw_path,"example_submission.csv"))
test$future_price <- 0
year_num <- as.numeric(as.factor(year(as_date(train$current_date))))
# subset out only the columns to model
train
test
drops <-  c('id','future_date','current_date')
train <- train[, !drops, with = FALSE]
train
test <- test[, !drops, with = FALSE]
test
#save the response var because dummyVars will remove
train_y <- train$future_price
train_y
# work with dummies
dummies  <-  dummyVars(future_price ~ ., data = train)
View(train)
train <- predict(dummies, newdata = train)
test <- data.table(test)
train <- as.matrix(train)
train
?cv.glmnet
?glmnet
gl_model <- cv.glmnet(train, train_y, alpha = 1, family = "gaussian", foldid = year_num, nfolds = length(unique(year_num)))
plot(gl_model)
bestlam <- gl_model$lambda.min
log(bestlam)
#fit a logistic model
gl_model <- glmnet(train, train_y, alpha = 1,family="gaussian")
plot(gl_model)
#save model
saveRDS(gl_model,".gl_model.model")
test <- as.matrix(test)
View(test)
#use the full model
pred <- predict(gl_model, s = bestlam, newx = test)
rm(list = ls())
library(data.table)
library(caret)
library(Metrics)
library(glmnet)
library(plotmo)
library(lubridate)
interim_data_path = "~/Desktop/STAT380/themagic/project/volume/data/interim/"
model_path ="~/Desktop/STAT380/themagic/project/volume/models/"
submission_path = "~/Desktop/STAT380/themagicproject/volume/data/processed/"
raw_path = "~/Desktop/STAT380/themagic/project/volume/data/raw/"
train = fread(file.path(interim_data_path,"train_v1.csv"))
test = fread(file.path(interim_data_path,"test_v1.csv"))
example_sub = fread(file.path(raw_path,"example_submission.csv"))
test$future_price <- 0
year_num <- as.numeric(as.factor(year(as_date(train$current_date))))
# subset out only the columns to model
train
test
drops <-  c('id','future_date','current_date')
train <- train[, !drops, with = FALSE]
train
test <- test[, !drops, with = FALSE]
test
#save the response var because dummyVars will remove
train_y <- train$future_price
train_y
# work with dummies
dummies  <-  dummyVars(future_price ~ ., data = train)
train <- predict(dummies, newdata = train)
test <- predict(dummies, newdata = test)
train <- data.table(train)
test <- data.table(test)
########################
# Use cross validation #
########################
train <- as.matrix(train)
train
?cv.glmnet
?glmnet
gl_model <- cv.glmnet(train, train_y, alpha = 1, family = "gaussian", foldid = year_num, nfolds = length(unique(year_num)))
plot(gl_model)
bestlam <- gl_model$lambda.min
log(bestlam)
####################################
# fit the model to all of the data #
####################################
#now fit the full model
#fit a logistic model
gl_model <- glmnet(train, train_y, alpha = 1,family="gaussian")
plot(gl_model)
#save model
saveRDS(gl_model,".gl_model.model")
test <- as.matrix(test)
#use the full model
pred <- predict(gl_model, s = bestlam, newx = test)
View(pred)
example_sub$future_price <- pred
example_sub
#now we can write out a submission
#load in libraries
rm(list = ls())
library(data.table)
library(Metrics)
library(glmnet)
load("hitters.rdata")
load("hitters.rdata")
load("hitters.rdata")
#load in libraries
rm(list = ls())
library(data.table)
library(Metrics)
library(glmnet)
load("hitters.rdata")
View(hitters)
colnames(hitters)
dim(hitters)
#data.frame style
sum(is.na(hitters$Salary))
#data.table style
hitters[, sum(is.na(Salary))]
# remove all rows with NA in it
hitters = na.omit(hitters)
set.seed(31415)
idx = sample(1:nrow(hitters), nrow(hitters) * .7)
train = hitters[idx]
test  = hitters[!idx]
fit.lm = lm(Salary ~ ., data = train)
train.err = rmse(train$Salary, fit.lm$fitted.values)
pred.lm = predict(fit.lm, test)
test.err = rmse(test$Salary, pred.lm)
help(lm)
errors = data.table(method = "lm",
train.rmse = train.err,
test.rmse  = test.err,
coefs      = length(fit.lm$coefficients) - 1)
View(errors)
step.lm = step(fit.lm)
View(fit.lm)
summary(step.lm)
help(step)
#load in libraries
rm(list = ls())
library(data.table)
library(Metrics)
library(glmnet)
load("hitters.rdata")
hitters
colnames(hitters)
dim(hitters)
# There are 322 baseball hitters with their statistics
# Can we predict salary from the statistics?
# First, we need to remove the NA's from the Salary
#data.frame style
sum(is.na(hitters$Salary))
#data.table style
hitters[, sum(is.na(Salary))]
# remove all rows with NA in it
hitters = na.omit(hitters)
# Divide into testing and training sets:
set.seed(31415)
idx = sample(1:nrow(hitters), nrow(hitters) * .7)
train = hitters[idx]
test  = hitters[!idx]
fit.lm = lm(Salary ~ ., data = train)
train.err = rmse(train$Salary, fit.lm$fitted.values)
pred.lm = predict(fit.lm, test)
test.err = rmse(test$Salary, pred.lm)
errors = data.table(method = "lm",
train.rmse = train.err,
test.rmse  = test.err,
coefs      = length(fit.lm$coefficients) - 1)
# Not all predictors were significant (overfitting)
# So let's remove them automatically
step.lm = step(fit.lm)
summary(step.lm)
gtrain.err = rmse(train$Salary, step.lm$fitted.values)
pred.step = predict(step.lm, test)
test.err = rmse(test$Salary, pred.step)
errors = rbind(errors,
list("step",
train.err,
test.err,
length(step.lm$coefficients) - 1))
View(errors)
errors
y.train = train$Salary
x.train = as.data.table(model.matrix(Salary ~ ., train))
x.train
x.train[, "(Intercept)" := NULL]
x.train
y.test = test$Salary
x.test = as.data.table(model.matrix(Salary ~ ., test))
x.test[, "(Intercept)" := NULL]
# Let's do ridge regression
grid = exp(seq(-3, 10, length = 131))
cv.ridge = cv.glmnet(as.matrix(x.train), y.train, alpha = 0, lambda = grid)
plot(cv.ridge)
bestlam.ridge = cv.ridge$lambda.min
log(bestlam.ridge)
fit.ridge = glmnet(as.matrix(x.train), y.train, alpha = 0, lambda = grid)
idx = which(fit.ridge$lambda == bestlam.ridge)
fit.ridge$a0[idx]
fit.ridge$beta[, idx]
ridge.train = predict(fit.ridge, s = bestlam.ridge, newx = as.matrix(x.train))
ridge.test  = predict(fit.ridge, s = bestlam.ridge, newx = as.matrix(x.test))
ridge.train.err = rmse(train$Salary, ridge.train)
ridge.test.err  = rmse(test$Salary, ridge.test)
errors = rbind(errors,
list("ridge",
ridge.train.err,
ridge.test.err,
sum(fit.ridge$beta[, idx] != 0)))
View(errors)
plot(fit.ridge)
errors
cv.lasso = cv.glmnet(as.matrix(x.train), y.train, alpha = 1, lambda = grid)
plot(cv.lasso)
bestlam.lasso = cv.lasso$lambda.min
log(bestlam.lasso)
fit.lasso = glmnet(as.matrix(x.train), y.train, alpha = 1, lambda = grid)
idx = which(fit.lasso$lambda == bestlam.lasso)
fit.lasso$a0[idx]
fit.lasso$beta[, idx]
lasso.train = predict(fit.lasso, s = bestlam.lasso, newx = as.matrix(x.train))
lasso.test  = predict(fit.lasso, s = bestlam.lasso, newx = as.matrix(x.test))
lasso.train.err = rmse(train$Salary, lasso.train)
lasso.test.err  = rmse(test$Salary, lasso.test)
errors = rbind(errors,
list("lasso",
lasso.train.err,
lasso.test.err,
sum(fit.lasso$beta[, idx] != 0)))
plot(fit.lasso)
#load in libraries
rm(list = ls())
library(data.table)
library(Metrics)
library(glmnet)
load("hitters.rdata")
hitters
colnames(hitters)
dim(hitters)
# There are 322 baseball hitters with their statistics
# Can we predict salary from the statistics?
# First, we need to remove the NA's from the Salary
#data.frame style
sum(is.na(hitters$Salary))
#data.table style
hitters[, sum(is.na(Salary))]
# remove all rows with NA in it
hitters = na.omit(hitters)
# Divide into testing and training sets:
set.seed(31415)
idx = sample(1:nrow(hitters), nrow(hitters) * .7)
train = hitters[idx]
test  = hitters[!idx]
fit.lm = lm(Salary ~ ., data = train)
train.err = rmse(train$Salary, fit.lm$fitted.values)
pred.lm = predict(fit.lm, test)
test.err = rmse(test$Salary, pred.lm)
errors = data.table(method = "lm",
train.rmse = train.err,
test.rmse  = test.err,
coefs      = length(fit.lm$coefficients) - 1)
# Not all predictors were significant (overfitting)
# So let's remove them automatically
step.lm = step(fit.lm)
summary(step.lm)
gtrain.err = rmse(train$Salary, step.lm$fitted.values)
pred.step = predict(step.lm, test)
test.err = rmse(test$Salary, pred.step)
errors = rbind(errors,
list("step",
train.err,
test.err,
length(step.lm$coefficients) - 1))
errors
# Let's see what happens for Ridge and Lasso
# Ridge and Lasso functions don't have y ~ . input
# so we need to separate
y.train = train$Salary
x.train = as.data.table(model.matrix(Salary ~ ., train))
x.train
x.train[, "(Intercept)" := NULL]
x.train
y.test = test$Salary
x.test = as.data.table(model.matrix(Salary ~ ., test))
x.test[, "(Intercept)" := NULL]
# Let's do ridge regression
grid = exp(seq(-3, 10, length = 131))
cv.ridge = cv.glmnet(as.matrix(x.train), y.train, alpha = 0, lambda = grid)
plot(cv.ridge)
bestlam.ridge = cv.ridge$lambda.min
log(bestlam.ridge)
fit.ridge = glmnet(as.matrix(x.train), y.train, alpha = 0, lambda = grid)
idx = which(fit.ridge$lambda == bestlam.ridge)
fit.ridge$a0[idx]
fit.ridge$beta[, idx]
ridge.train = predict(fit.ridge, s = bestlam.ridge, newx = as.matrix(x.train))
ridge.test  = predict(fit.ridge, s = bestlam.ridge, newx = as.matrix(x.test))
ridge.train.err = rmse(train$Salary, ridge.train)
ridge.test.err  = rmse(test$Salary, ridge.test)
errors = rbind(errors,
list("ridge",
ridge.train.err,
ridge.test.err,
sum(fit.ridge$beta[, idx] != 0)))
plot(fit.ridge)
errors
# Let's do lasso regression since that can set coefficients to 0
cv.lasso = cv.glmnet(as.matrix(x.train), y.train, alpha = 1, lambda = grid)
plot(cv.lasso)
bestlam.lasso = cv.lasso$lambda.min
log(bestlam.lasso)
fit.lasso = glmnet(as.matrix(x.train), y.train, alpha = 1, lambda = grid)
idx = which(fit.lasso$lambda == bestlam.lasso)
fit.lasso$a0[idx]
fit.lasso$beta[, idx]
lasso.train = predict(fit.lasso, s = bestlam.lasso, newx = as.matrix(x.train))
lasso.test  = predict(fit.lasso, s = bestlam.lasso, newx = as.matrix(x.test))
lasso.train.err = rmse(train$Salary, lasso.train)
lasso.test.err  = rmse(test$Salary, lasso.test)
errors = rbind(errors,
list("lasso",
lasso.train.err,
lasso.test.err,
sum(fit.lasso$beta[, idx] != 0)))
plot(fit.lasso)
print(errors)
