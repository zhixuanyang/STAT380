train_3 <- data.table(train_3)
test_3 <- data.table(test_3)
########################
# Use cross validation #
########################
train <- as.matrix(train)
train_1 <- as.matrix(train_1)
train_2 <- as.matrix(train_2)
train_3 <- as.matrix(train_3)
test <- as.matrix(test)
test_1 <- as.matrix(test_1)
test_2 <- as.matrix(test_2)
test_3 <- as.matrix(test_3)
gl_model_1 <- glmnet(train_1, train_1y, alpha = 1, family = "gaussian")
error_DT <- NULL
for (i in 1:length(unclass(gl_model_1)$lambda)) {
model_lambda <- unclass(gl_model_1)$lambda[i]
pred <- predict(gl_model_1, s = model_lambda, newx = test_1)
error <- rmse(pred[, 1], test_1y)
new_row <- c(model_lambda, error)
error_DT <- rbind(error_DT, new_row)
}
error_DT_1 <- data.table(error_DT)
setnames(error_DT_1, c("V1", "V2"), c("lambda", "error"))
gl_model_2 <- glmnet(train_2, train_2y, alpha = 1, family = "gaussian")
error_DT <- NULL
for (i in 1:length(unclass(gl_model_2)$lambda)) {
model_lambda <- unclass(gl_model_2)$lambda[i]
pred <- predict(gl_model_2, s = model_lambda, newx = test_2)
error <- rmse(pred[, 1], test_2y)
new_row <- c(model_lambda, error)
error_DT <- rbind(error_DT, new_row)
}
error_DT_2 <- data.table(error_DT)
setnames(error_DT_2, c("V1", "V2"), c("lambda", "error"))
gl_model_3 <- glmnet(train_3, train_3y, alpha = 1, family = "gaussian")
error_DT <- NULL
for (i in 1:length(unclass(gl_model_3)$lambda)) {
model_lambda <- unclass(gl_model_3)$lambda[i]
pred <- predict(gl_model_3, s = model_lambda, newx = test_3)
error <- rmse(pred[, 1], test_3y)
new_row <- c(model_lambda, error)
error_DT <- rbind(error_DT, new_row)
}
error_DT_3 <- data.table(error_DT)
setnames(error_DT_3, c("V1", "V2"), c("lambda", "error"))
error_DT_1$set <- "2018-04-27"
error_DT_2$set <- "2018-07-13"
error_DT_3$set <- "2018-10-05"
error_DT_full <- rbind(error_DT_1, error_DT_2, error_DT_3)
ggplot(error_DT_full, aes(x = log(lambda), y = error, col = set)) + geom_smooth()
lambda_1 <- error_DT_1$lambda[which.min(error_DT_1$error)]
lambda_2 <- error_DT_2$lambda[which.min(error_DT_1$error)]
lambda_3 <- error_DT_3$lambda[which.min(error_DT_1$error)]
lambda_1
lambda_2
lambda_3
# lambda_1 <- error_DT_full[error == min(error_DT_1$error)]$lambda
# lambda_2 <- error_DT_full[error == min(error_DT_2$error)]$lambda
# lambda_3 <- error_DT_full[error == min(error_DT_3$error)]$lambda
all_best_lambdas <- c(lambda_1, lambda_2, lambda_3)
bestlam <- mean(all_best_lambdas)
####################################
# fit the model to all of the data #
####################################
#now fit the full model
#fit a logistic model
gl_model <- glmnet(train, train_y, alpha = 1, family = "gaussian")
plot(gl_model)
#save model
saveRDS(gl_model, "gl_model.model")
test <- as.matrix(test)
#use the full model
pred <- predict(gl_model, s = bestlam, newx = test)
bestlam
predict(gl_model, s = bestlam, newx = test, type = "coefficients")
gl_model
View(error_DT_full)
View(error_DT_full)
error_DT_full[error == min(error_DT_1$error)]
error_DT_full[error == min(error_DT_2$error)]
error_DT_full[error == min(error_DT_3$error)]
example_sub$future_price <- pred
#now we can write out a submission
fwrite(example_sub,file.path(submission_path,"submit_17.csv"))
View(train)
rm(list = ls())
library(data.table)
library(caret)
library(Metrics)
library(glmnet)
library(plotmo)
library(lubridate)
interim_data_path = "~/Desktop/STAT380/themagic2/project/volume/data/interim/"
model_path ="~/Desktop/STAT380/themagic2/project/volume/models/"
submission_path = "~/Desktop/STAT380/themagic2/project/volume/data/processed/"
raw_path = "~/Desktop/STAT380/themagic2/project/volume/data/raw/"
train = fread(file.path(interim_data_path,"train_extra.csv"))
test = fread(file.path(interim_data_path,"test_extra.csv"))
example_sub = fread(file.path(raw_path,"example_submission.csv"))
View(train)
train$current_date <- as_date(train$current_date)
train <- train[order(-current_date)]
library(data.table)
library(Metrics)
library(caret)
library(glmnet)
zeros = c()
rm(list = ls())
library(data.table)
library(Metrics)
library(caret)
library(glmnet)
# Question from Class: What is the probability of a random matrix begin intervitble?
zeros = c()
zeros = c()
for (n in 1:30) {
q = c()
for (i in 1:10000) {
M = matrix(sample(c(0, 1), n^2, replace = TRUE), n, n)
d = round(det(M), 0)
q = c(q, d)
}
totzero = sum(q == 0)
zeros = c(zeros, totzero)
cat(sum(q == 0), " / 10,000\n")
hist(q)
}
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
# There are 2419 obs in the training set.
# Let's pump up the number of features to 2,500
n = 2500 - (ncol(data) - 1)
n
rm(list = ls())
library(data.table)
library(Metrics)
library(caret)
library(glmnet)
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
# There are 2419 obs in the training set.
# Let's pump up the number of features to 2,500
n = 2500 - (ncol(data) - 1)
n
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
n = 2500 - (ncol(data) - 1)
# What happens to MSE and RSE as number of features increases?
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
# There are 2419 obs in the training set.
# Let's pump up the number of features to 2,500
n = 2500 - (ncol(data))
n
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
# There are 2419 obs in the training set.
# Let's pump up the number of features to 2,500
n = 2500 - (ncol(data)-1)
n
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
# There are 2419 obs in the training set.
# Let's pump up the number of features to 2,500
n = 2500 - (ncol(data)-1)
n
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
# There are 2419 obs in the training set.
# Let's pump up the number of features to 2,500
n = 2500 - (ncol(data)-1)
n
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
# There are 2419 obs in the training set.
# Let's pump up the number of features to 2,500
n = 2500 - (ncol(data)-1)
n
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
# There are 2419 obs in the training set.
# Let's pump up the number of features to 2,500
n = 2500 - (ncol(data)-1)
n
M = as.data.frame(matrix(sample(c(0, 1), n * nrow(data), replace = TRUE), ncol = n))
View(data)
setnames(M, paste0("Extra_", 501:(500 + 1990)))
colnames(M)
data = cbind(data, M)
train = data[idx]
test  = data[!idx]
sizes = c(10, seq(50, 500, 50), seq(1000, 2500, 500))
sizes
results = c()
for (size in sizes) {
cat("size = ", size, "\n")
fit = lm(future_price ~ ., data = train[, 1:(size + 1)])
pred = predict(fit, test, type = "response")
results = rbind(results, data.table(size = size,
train.rmse    = rmse(train$future_price, fit$fitted.values),
train.r.sqr   = summary(fit)$r.squared,
train.adj.r.sqr = summary(fit)$adj.r.squared,
test.rmse     = rmse(test$future_price, pred)))
}
help(seq)
help(cat)
results
plot(train.r.sqr ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "r^2")
plot(train.adj.r.sqr ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "adj r^2")
plot(train.rmse ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "training rmse")
plot(test.rms ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "testing rmse")
fit.forward = step(fit, direction = "forward")
rm(list = ls())
library(data.table)
library(Metrics)
library(caret)
library(glmnet)
# Question from Class: What is the probability of a random matrix begin intervitble?
zeros = c()
for (n in 1:30) {
q = c()
for (i in 1:10000) {
M = matrix(sample(c(0, 1), n^2, replace = TRUE), n, n)
d = round(det(M), 0)
q = c(q, d)
}
totzero = sum(q == 0)
zeros = c(zeros, totzero)
cat(sum(q == 0), " / 10,000\n")
hist(q)
}
print(zeros)
plot(zeros / 10000, xlab = "dim(M)", ylab = "% non-invertible")
# What happens to MSE and RSE as number of features increases?
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
# There are 2419 obs in the training set.
# Let's pump up the number of features to 2,500
n = 2500 - (ncol(data)-1)
n
# We need to add 1990 extra features.  Chances are these will be linearly independent
M = as.data.frame(matrix(sample(c(0, 1), n * nrow(data), replace = TRUE), ncol = n))
setnames(M, paste0("Extra_", 501:(500 + 1990)))
colnames(M)
data = cbind(data, M)
train = data[idx]
test  = data[!idx]
sizes = c(10, seq(50, 500, 50), seq(1000, 2500, 500))
sizes
results = c()
for (size in sizes) {
cat("size = ", size, "\n")
fit = lm(future_price ~ ., data = train[, 1:(size + 1)])
pred = predict(fit, test, type = "response")
results = rbind(results, data.table(size = size,
train.rmse    = rmse(train$future_price, fit$fitted.values),
train.r.sqr   = summary(fit)$r.squared,
train.adj.r.sqr = summary(fit)$adj.r.squared,
test.rmse     = rmse(test$future_price, pred)))
}
results
plot(train.r.sqr ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "r^2")
plot(train.adj.r.sqr ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "adj r^2")
plot(train.rmse ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "training rmse")
plot(test.rms ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "testing rmse")
# Moral: be careful with high dimensions!
# Forward stepwise selection
# Ridge Regression
# Lasso Regression
# are all useful when preforming regression in high-dimensions
# Note, both forward and backward stepwise selection fail since we have *PERFECT* fits
fit.forward = step(fit, direction = "forward")
fit.backward = step(fit, direction = "backward")
rm(list = ls())
library(data.table)
library(Metrics)
library(caret)
library(glmnet)
# Question from Class: What is the probability of a random matrix begin intervitble?
zeros = c()
for (n in 1:30) {
q = c()
for (i in 1:10000) {
M = matrix(sample(c(0, 1), n^2, replace = TRUE), n, n)
d = round(det(M), 0)
q = c(q, d)
}
totzero = sum(q == 0)
zeros = c(zeros, totzero)
cat(sum(q == 0), " / 10,000\n")
hist(q)
}
print(zeros)
plot(zeros / 10000, xlab = "dim(M)", ylab = "% non-invertible")
# What happens to MSE and RSE as number of features increases?
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
# There are 2419 obs in the training set.
# Let's pump up the number of features to 2,500
n = 2500 - (ncol(data)-1)
n
# We need to add 1990 extra features.  Chances are these will be linearly independent
M = as.data.frame(matrix(sample(c(0, 1), n * nrow(data), replace = TRUE), ncol = n))
setnames(M, paste0("Extra_", 501:(500 + 1990)))
colnames(M)
data = cbind(data, M)
train = data[idx]
test  = data[!idx]
sizes = c(10, seq(50, 500, 50), seq(1000, 2500, 500))
sizes
results = c()
for (size in sizes) {
cat("size = ", size, "\n")
fit = lm(future_price ~ ., data = train[, 1:(size + 1)])
pred = predict(fit, test, type = "response")
results = rbind(results, data.table(size = size,
train.rmse    = rmse(train$future_price, fit$fitted.values),
train.r.sqr   = summary(fit)$r.squared,
train.adj.r.sqr = summary(fit)$adj.r.squared,
test.rmse     = rmse(test$future_price, pred)))
}
results
plot(train.r.sqr ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "r^2")
plot(train.adj.r.sqr ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "adj r^2")
plot(train.rmse ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "training rmse")
plot(test.rms ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "testing rmse")
y.train = train$future_price
y.test  = test$future_price
dummies = dummyVars(future_price ~ ., data = data)
train <- predict(dummies, newdata = train)
test <- predict(dummies, newdata = test)
real.data.idx = 1:13
real.data.idx
rm(list = ls())
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
View(data)
data = fread("train_extra.csv")
remove = c("id", "current_date", "future_date")
data[, (remove) := NULL]
# Split the data into two equal sized train and test
idx = sample(1:nrow(data), nrow(data) / 2)
length(idx)
# There are 2419 obs in the training set.
# Let's pump up the number of features to 2,500
n = 2500 - (ncol(data)-1)
n
# We need to add 1990 extra features.  Chances are these will be linearly independent
M = as.data.frame(matrix(sample(c(0, 1), n * nrow(data), replace = TRUE), ncol = n))
setnames(M, paste0("Extra_", 501:(500 + 1990)))
colnames(M)
data = cbind(data, M)
train = data[idx]
test  = data[!idx]
sizes = c(10, seq(50, 500, 50), seq(1000, 2500, 500))
sizes
results = c()
for (size in sizes) {
cat("size = ", size, "\n")
fit = lm(future_price ~ ., data = train[, 1:(size + 1)])
pred = predict(fit, test, type = "response")
results = rbind(results, data.table(size = size,
train.rmse    = rmse(train$future_price, fit$fitted.values),
train.r.sqr   = summary(fit)$r.squared,
train.adj.r.sqr = summary(fit)$adj.r.squared,
test.rmse     = rmse(test$future_price, pred)))
}
results
plot(train.r.sqr ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "r^2")
plot(train.adj.r.sqr ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "adj r^2")
plot(train.rmse ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "training rmse")
plot(test.rms ~ size, data = results, type = "l",
xlab = "number of covariates", ylab = "testing rmse")
# Moral: be careful with high dimensions!
# Forward stepwise selection
# Ridge Regression
# Lasso Regression
# are all useful when preforming regression in high-dimensions
y.train = train$future_price
y.test  = test$future_price
dummies = dummyVars(future_price ~ ., data = data)
train <- predict(dummies, newdata = train)
test <- predict(dummies, newdata = test)
real.data.idx = 1:13
gl.train.real <- cv.glmnet(train[, real.data.idx],
y.train,
nfolds = 50,
alpha = 1,
family = "gaussian")
gl.train.all <- cv.glmnet(train,
y.train,
nfolds = 50,
alpha = 1,
family = "gaussian")
bestlam.real = gl.train.real$lambda.min
bestlam.all  = gl.train.all$lambda.min
gl.train.real <- cv.glmnet(train[, real.data.idx],
y.train,
nfolds = 50,
alpha = 1,
family = "gaussian")
rm(list = ls())
rm(list = ls())
library(data.table)
library(Metrics)
library(caret)
library(glmnet)
